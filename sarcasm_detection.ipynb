{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarcasm_detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfTGyC8lyn7_",
        "colab_type": "text"
      },
      "source": [
        "# Import of libraries and files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ybk7r4rx5_A",
        "colab_type": "code",
        "outputId": "df1b2435-d9f1-43f3-f3fa-06b8377836c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from collections import Counter\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from xgboost.sklearn import XGBClassifier, XGBRegressor\n",
        "from sklearn.metrics import accuracy_score, r2_score, mean_absolute_error, mean_squared_error\n",
        "from __future__ import print_function\n",
        "import scipy.stats as ss\n",
        "from sklearn.externals import joblib\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from gensim.models import Word2Vec, word2vec\n",
        "from gensim.utils import simple_preprocess\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Dense, Dropout, Embedding, SimpleRNN, LSTM, Bidirectional, MaxPooling1D, Conv1D\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.utils import np_utils, to_categorical \n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "! pip install ndjson\n",
        "import ndjson\n",
        "import json"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ndjson in /usr/local/lib/python3.6/dist-packages (0.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbgKD3HJym4L",
        "colab_type": "code",
        "outputId": "99669e6f-d43d-4607-db23-6187563c9ede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzZbIMuZza-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data is in new line delimited json format so I use ndjson library to open it\n",
        "ndjson_file = '/content/gdrive/My Drive/zadanie_Roche/data.json'\n",
        "with open(ndjson_file) as f:  \n",
        "    data = ndjson.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMi6OpqV0HF3",
        "colab_type": "code",
        "outputId": "d46489f7-8542-4b5b-8f61-0f4578d0d8d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "data[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'headline': \"former versace store clerk sues over secret 'black code' for minority shoppers\",\n",
              "  'is_sarcastic': 0},\n",
              " {'headline': \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\",\n",
              "  'is_sarcastic': 0},\n",
              " {'headline': \"mom starting to fear son's web series closest thing she will have to grandchild\",\n",
              "  'is_sarcastic': 1},\n",
              " {'headline': 'boehner just wants wife to listen, not come up with alternative debt-reduction ideas',\n",
              "  'is_sarcastic': 1},\n",
              " {'headline': 'j.k. rowling wishes snape happy birthday in the most magical way',\n",
              "  'is_sarcastic': 0},\n",
              " {'headline': \"advancing the world's women\", 'is_sarcastic': 0},\n",
              " {'headline': 'the fascinating case for eating lab-grown meat',\n",
              "  'is_sarcastic': 0},\n",
              " {'headline': 'this ceo will send your kids to school, if you work for his company',\n",
              "  'is_sarcastic': 0},\n",
              " {'headline': 'top snake handler leaves sinking huckabee campaign',\n",
              "  'is_sarcastic': 1},\n",
              " {'headline': \"friday's morning email: inside trump's presser for the ages\",\n",
              "  'is_sarcastic': 0}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBbxgfBbcYKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json_file = '/content/gdrive/My Drive/zadanie_Roche/data_final.json'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Pw6kDPO9MlD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving in proper json file so that pandas can read it\n",
        "with open(json_file, \"w\") as f:  \n",
        "    json.dump(data, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3unIfvh5ri3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_json(json_file, orient=\"records\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDDE-BvI7TzP",
        "colab_type": "code",
        "outputId": "243efb2a-3cff-466c-c901-91861b9ec270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  is_sarcastic\n",
              "0  former versace store clerk sues over secret 'b...             0\n",
              "1  the 'roseanne' revival catches up to our thorn...             0\n",
              "2  mom starting to fear son's web series closest ...             1\n",
              "3  boehner just wants wife to listen, not come up...             1\n",
              "4  j.k. rowling wishes snape happy birthday in th...             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0dpdQVYABrW",
        "colab_type": "code",
        "outputId": "e901904c-f5e7-4e48-8dcb-738caa7f3e0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f'There are {data.shape[0]} headlines')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 26709 headlines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-6aA208NV_T",
        "colab_type": "code",
        "outputId": "1cad7900-494c-4463-97a7-a12b10a49152",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# checking number of sarcastic and non-sarcastic comments\n",
        "data['is_sarcastic'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    14985\n",
              "1    11724\n",
              "Name: is_sarcastic, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ8mrCL3No2_",
        "colab_type": "text"
      },
      "source": [
        "Classes are rather balanced so accuracy can be used as classification metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNJ5huWPArQc",
        "colab_type": "text"
      },
      "source": [
        "##Assigning variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRQ9xaIBAnSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data[\"headline\"]\n",
        "y = data[\"is_sarcastic\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, \n",
        "                                                          random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, \n",
        "                                                          random_state=52)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amk8ijVect0U",
        "colab_type": "text"
      },
      "source": [
        "# 1st approach: topic modelling (LDA) + Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZN2cl-n_442",
        "colab_type": "text"
      },
      "source": [
        "# 2nd approach: pretrained Embeddings + LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-87_DLwY5nIJ",
        "colab_type": "text"
      },
      "source": [
        "## Text preprocessing for LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPmVWJ5i5rBV",
        "colab_type": "code",
        "outputId": "929d2ffa-88e6-465c-8cdf-31f27d037305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# tokenizing and filtering out basic punctuation\n",
        "# I won't turn words to lowercase as I will use cased GloVe embeddings\n",
        "# so that \"Bush\" can have a different embedding from \"bush\"\n",
        "tokenizer = Tokenizer(lower=False)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# dictionary mapping words (str) to their index (int)\n",
        "word_index = tokenizer.word_index\n",
        "print(f\"Found {len(word_index)} unique tokens.\")\n",
        "\n",
        "# turning texts into sequences (list of word indexes)\n",
        "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
        "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
        "sequences_val = tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "# checking the length of the longest headline\n",
        "max_len = max([len(x) for x in sequences_train+sequences_val+sequences_test])\n",
        "print(f\"The longest headline has {max_len} words.\")\n",
        "\n",
        "# padding sequences so that they are of equal length\n",
        "X_train_nn = sequence.pad_sequences(sequences_train, max_len)\n",
        "X_test_nn = sequence.pad_sequences(sequences_test, max_len)\n",
        "X_val_nn = sequence.pad_sequences(sequences_val, max_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25218 unique tokens.\n",
            "The longest headline has 40 words.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPD8wMx9IDpw",
        "colab_type": "text"
      },
      "source": [
        "## Loading and filtering embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD4EHAKDASmJ",
        "colab_type": "text"
      },
      "source": [
        "Almost 27 000 headlines don't seem enough data to train powerful word-embeddings on them. I will use pre-trained GloVe embedings trained on Common Crawl corpus with 840B tokens and 2.2M vocab, cased. I will load it from a pickled file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37HDytnp_y6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_embeddings(path):\n",
        "    '''Function to load pre-trained embeddings from pickled file.'''\n",
        "    with open(path,'rb') as f:\n",
        "        emb_arr = joblib.load(f)\n",
        "    return emb_arr\n",
        "  \n",
        "def build_matrix(word_index, path):\n",
        "    '''Function to bild matrix with embeddings for words in our vocabulary'''\n",
        "    emb_index = load_embeddings(path)\n",
        "    emb_matrix = np.zeros((len(word_index), 300))\n",
        "    unknown_words = []\n",
        "    \n",
        "    for w, i in word_index.items():\n",
        "      try:\n",
        "        vect = emb_index[w]\n",
        "        if vect is not None:\n",
        "          emb_matrix[i] = vect\n",
        "      except:\n",
        "        unknown_words.append(w)\n",
        "    return emb_matrix, unknown_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCXgw0jP_Olt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_ebeddings = '/content/gdrive/My Drive/zadanie_Roche/glove.840B.300d.pkl'\n",
        "emb_matrix, unknown_words = build_matrix(word_index, path_to_ebeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_sh88wuF7Y6",
        "colab_type": "code",
        "outputId": "ec177e41-a777-439c-f123-1a9dbd6049c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('% of unknown words: ', len(unknown_words)/len(word_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of unknown words:  0.1823300816876834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwcM_0vIGXAF",
        "colab_type": "text"
      },
      "source": [
        "Only less than 20% of words don't have embedding, that's a promising output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9Ac3K64-3u3",
        "colab_type": "code",
        "outputId": "597b1ebc-effa-4b2b-8a75-619c882ed57a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# saving matrix with filtered embeddings \n",
        "joblib.dump(emb_matrix, \"emb_matrix.joblib\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emb_matrix.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2ipNdoqCwsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# opening matrix with filtered embeddings from disc\n",
        "emb_matrix = joblib.load(\"/content/gdrive/My Drive/zadanie_Roche/emb_matrix.joblib\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y9ezUOjIHpY",
        "colab_type": "text"
      },
      "source": [
        "## Training NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsbLNbv7INaZ",
        "colab_type": "text"
      },
      "source": [
        "Preprocessed texts and embeddings can be fed into Neural Network. I test several different architectures basing on LSTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bWIUxdQGkUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_lstm_model(list_of_layers):\n",
        "  \n",
        "  model = Sequential()\n",
        "  model.add(Embedding(emb_matrix.shape[0],\n",
        "                      emb_matrix.shape[1], \n",
        "                      input_length=max_len,\n",
        "                      weights = [emb_matrix], \n",
        "                      trainable = False))\n",
        "  for layer in list_of_layers:\n",
        "    model.add(layer)\n",
        "  model.summary() \n",
        "  \n",
        "  model.compile(loss=\"binary_crossentropy\",\n",
        "               optimizer=\"adam\", \n",
        "               metrics=[\"binary_accuracy\"])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uetMWHsxLgl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_lstm_model(model, X_train, X_val, y_train, y_val, filename, batch_size=32, early_stopping=False):\n",
        "\n",
        "  take_best_model = ModelCheckpoint(str(filename)+\".h5py\", save_best_only=True)\n",
        "  \n",
        "  if early_stopping == True:\n",
        "    early_stopping = EarlyStopping(patience=10, monitor=\"val_loss\")\n",
        "    history = model.fit(X_train, y_train, epochs=50, validation_split=0.2,\n",
        "              batch_size=batch_size, \n",
        "              callbacks=[early_stopping, take_best_model])\n",
        "   \n",
        "  else:\n",
        "    history = model.fit(X_train, y_train, epochs=50, validation_split=0.2,\n",
        "              batch_size=batch_size, \n",
        "              callbacks=[take_best_model])\n",
        "  \n",
        "  joblib.dump(history, filename)\n",
        "\n",
        "  model.load_weights(str(filename)+\".h5py\")\n",
        "  return model.evaluate(X_val, y_val)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIXeMaOvaedp",
        "colab_type": "text"
      },
      "source": [
        "Following architectures might be too extensive for the given problem but first I want to check if they overfit and if they do, I will prune them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEpGOqYUULtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = {        \n",
        "          \"LSTM_200_100_50\":      [LSTM(200, return_sequences=True),\n",
        "                             LSTM(100, return_sequences=True),\n",
        "                             LSTM(50),\n",
        "                                  Dense(1, activation=\"sigmoid\")],\n",
        "          \n",
        "          \"BiLSTM_100_50\":          [Bidirectional(LSTM(100, return_sequences=True)),\n",
        "                                     Bidirectional(LSTM(50)),\n",
        "                                  Dense(1, activation=\"sigmoid\")],\n",
        "          \n",
        "          \"LSTM_200_100\":    [LSTM(200, return_sequences=True),\n",
        "                                  LSTM(100),\n",
        "                                  Dense(1, activation=\"sigmoid\")],\n",
        "          \n",
        "          \"LSTM_MultipleDense\":     [LSTM(200, return_sequences=True),\n",
        "                                  LSTM(100),\n",
        "                                  Dense(30, activation=\"relu\"),\n",
        "                                  Dense(1, activation=\"sigmoid\")],\n",
        "     \n",
        "         \n",
        "          \"Conv_Pool_LSTM\": [Conv1D(64,3),\n",
        "                                   MaxPooling1D(pool_size=2),\n",
        "                                   LSTM(100),\n",
        "                                   Dense(1, activation=\"sigmoid\")],\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H4D2mClNCuY",
        "colab_type": "code",
        "outputId": "e0757074-a4ea-4fc6-8039-b2c1d4a57bc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1547
        }
      },
      "source": [
        "lst = []\n",
        "for model, params in models.items():\n",
        "  acc = (evaluate_lstm_model(build_lstm_model(params), X_train_nn, X_val_nn, y_train, y_val, model, early_stopping=False))\n",
        "  lst.append(acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 40, 300)           7565400   \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 40, 200)           400800    \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 40, 100)           120400    \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 50)                30200     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 8,116,851\n",
            "Trainable params: 551,451\n",
            "Non-trainable params: 7,565,400\n",
            "_________________________________________________________________\n",
            "Train on 15436 samples, validate on 3860 samples\n",
            "Epoch 1/50\n",
            "15436/15436 [==============================] - 96s 6ms/step - loss: 0.1573 - binary_accuracy: 0.9386 - val_loss: 0.3282 - val_binary_accuracy: 0.8767\n",
            "Epoch 2/50\n",
            "15436/15436 [==============================] - 93s 6ms/step - loss: 0.1017 - binary_accuracy: 0.9633 - val_loss: 0.4131 - val_binary_accuracy: 0.8738\n",
            "Epoch 3/50\n",
            "15436/15436 [==============================] - 92s 6ms/step - loss: 0.0658 - binary_accuracy: 0.9771 - val_loss: 0.4761 - val_binary_accuracy: 0.8767\n",
            "Epoch 4/50\n",
            "15436/15436 [==============================] - 92s 6ms/step - loss: 0.0400 - binary_accuracy: 0.9867 - val_loss: 0.5990 - val_binary_accuracy: 0.8604\n",
            "Epoch 5/50\n",
            "15436/15436 [==============================] - 92s 6ms/step - loss: 0.0337 - binary_accuracy: 0.9881 - val_loss: 0.5314 - val_binary_accuracy: 0.8754\n",
            "Epoch 6/50\n",
            "15436/15436 [==============================] - 92s 6ms/step - loss: 0.0252 - binary_accuracy: 0.9919 - val_loss: 0.5637 - val_binary_accuracy: 0.8720\n",
            "Epoch 7/50\n",
            "15436/15436 [==============================] - 92s 6ms/step - loss: 0.0208 - binary_accuracy: 0.9929 - val_loss: 0.6705 - val_binary_accuracy: 0.8731\n",
            "Epoch 8/50\n",
            "15436/15436 [==============================] - 91s 6ms/step - loss: 0.0211 - binary_accuracy: 0.9925 - val_loss: 0.5837 - val_binary_accuracy: 0.8720\n",
            "Epoch 9/50\n",
            "15436/15436 [==============================] - 92s 6ms/step - loss: 0.0171 - binary_accuracy: 0.9944 - val_loss: 0.5936 - val_binary_accuracy: 0.8788\n",
            "Epoch 10/50\n",
            "15436/15436 [==============================] - 91s 6ms/step - loss: 0.0141 - binary_accuracy: 0.9952 - val_loss: 0.6474 - val_binary_accuracy: 0.8720\n",
            "Epoch 11/50\n",
            "15436/15436 [==============================] - 92s 6ms/step - loss: 0.0146 - binary_accuracy: 0.9958 - val_loss: 0.6570 - val_binary_accuracy: 0.8692\n",
            "Epoch 12/50\n",
            "15436/15436 [==============================] - 91s 6ms/step - loss: 0.0131 - binary_accuracy: 0.9957 - val_loss: 0.7243 - val_binary_accuracy: 0.8782\n",
            "Epoch 13/50\n",
            "15436/15436 [==============================] - 92s 6ms/step - loss: 0.0119 - binary_accuracy: 0.9957 - val_loss: 0.6071 - val_binary_accuracy: 0.8731\n",
            "Epoch 14/50\n",
            "15436/15436 [==============================] - 91s 6ms/step - loss: 0.0132 - binary_accuracy: 0.9953 - val_loss: 0.6189 - val_binary_accuracy: 0.8725\n",
            "Epoch 15/50\n",
            "15436/15436 [==============================] - 91s 6ms/step - loss: 0.0052 - binary_accuracy: 0.9988 - val_loss: 0.6811 - val_binary_accuracy: 0.8762\n",
            "Epoch 16/50\n",
            "15436/15436 [==============================] - 92s 6ms/step - loss: 0.0056 - binary_accuracy: 0.9984 - val_loss: 0.6344 - val_binary_accuracy: 0.8772\n",
            "Epoch 17/50\n",
            "15436/15436 [==============================] - 92s 6ms/step - loss: 0.0125 - binary_accuracy: 0.9959 - val_loss: 0.6614 - val_binary_accuracy: 0.8782\n",
            "Epoch 18/50\n",
            "15436/15436 [==============================] - 91s 6ms/step - loss: 0.0049 - binary_accuracy: 0.9989 - val_loss: 0.7787 - val_binary_accuracy: 0.8573\n",
            "Epoch 19/50\n",
            "15436/15436 [==============================] - 92s 6ms/step - loss: 0.0211 - binary_accuracy: 0.9944 - val_loss: 0.6161 - val_binary_accuracy: 0.8694\n",
            "Epoch 20/50\n",
            "15436/15436 [==============================] - 91s 6ms/step - loss: 0.0085 - binary_accuracy: 0.9975 - val_loss: 0.6689 - val_binary_accuracy: 0.8699\n",
            "Epoch 21/50\n",
            "15436/15436 [==============================] - 92s 6ms/step - loss: 0.0065 - binary_accuracy: 0.9983 - val_loss: 0.6457 - val_binary_accuracy: 0.8775\n",
            "Epoch 22/50\n",
            "15436/15436 [==============================] - 91s 6ms/step - loss: 0.0081 - binary_accuracy: 0.9972 - val_loss: 0.7532 - val_binary_accuracy: 0.8756\n",
            "Epoch 23/50\n",
            "15436/15436 [==============================] - 92s 6ms/step - loss: 0.0073 - binary_accuracy: 0.9974 - val_loss: 0.6954 - val_binary_accuracy: 0.8790\n",
            "Epoch 24/50\n",
            "15436/15436 [==============================] - 91s 6ms/step - loss: 0.0062 - binary_accuracy: 0.9981 - val_loss: 0.7026 - val_binary_accuracy: 0.8808\n",
            "Epoch 25/50\n",
            "15436/15436 [==============================] - 91s 6ms/step - loss: 0.0068 - binary_accuracy: 0.9976 - val_loss: 0.7156 - val_binary_accuracy: 0.8741\n",
            "Epoch 26/50\n",
            "15436/15436 [==============================] - 91s 6ms/step - loss: 0.0098 - binary_accuracy: 0.9971 - val_loss: 0.6282 - val_binary_accuracy: 0.8788\n",
            "Epoch 27/50\n",
            "15436/15436 [==============================] - 92s 6ms/step - loss: 0.0091 - binary_accuracy: 0.9964 - val_loss: 0.7255 - val_binary_accuracy: 0.8712\n",
            "Epoch 28/50\n",
            "15436/15436 [==============================] - 91s 6ms/step - loss: 0.0054 - binary_accuracy: 0.9984 - val_loss: 0.7036 - val_binary_accuracy: 0.8728\n",
            "Epoch 29/50\n",
            "15436/15436 [==============================] - 92s 6ms/step - loss: 0.0055 - binary_accuracy: 0.9976 - val_loss: 0.7196 - val_binary_accuracy: 0.8733\n",
            "Epoch 30/50\n",
            "15436/15436 [==============================] - 91s 6ms/step - loss: 0.0031 - binary_accuracy: 0.9992 - val_loss: 0.8389 - val_binary_accuracy: 0.8759\n",
            "Epoch 31/50\n",
            "15436/15436 [==============================] - 92s 6ms/step - loss: 0.0087 - binary_accuracy: 0.9974 - val_loss: 0.6203 - val_binary_accuracy: 0.8767\n",
            "Epoch 32/50\n",
            "15436/15436 [==============================] - 91s 6ms/step - loss: 0.0058 - binary_accuracy: 0.9984 - val_loss: 0.7264 - val_binary_accuracy: 0.8687\n",
            "Epoch 33/50\n",
            "15436/15436 [==============================] - 92s 6ms/step - loss: 0.0049 - binary_accuracy: 0.9985 - val_loss: 0.7981 - val_binary_accuracy: 0.8720\n",
            "Epoch 34/50\n",
            "15436/15436 [==============================] - 91s 6ms/step - loss: 0.0071 - binary_accuracy: 0.9975 - val_loss: 0.7436 - val_binary_accuracy: 0.8718\n",
            "Epoch 35/50\n",
            "15436/15436 [==============================] - 92s 6ms/step - loss: 5.5332e-04 - binary_accuracy: 0.9998 - val_loss: 0.8951 - val_binary_accuracy: 0.8731\n",
            "Epoch 36/50\n",
            "12864/15436 [========================>.....] - ETA: 14s - loss: 4.6774e-05 - binary_accuracy: 1.0000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjkUajwNsjNI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkSypmGZNQvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accuracy(path, models):\n",
        "  '''Function to plot accuracy on train and validation sets.'''\n",
        "  for model in models:\n",
        "    history = joblib.load(os.path.join(path_to_results, model))\n",
        "    plt.plot(history.history['binary_accuracy'])\n",
        "    plt.plot(history.history['val_binary_accuracy'])\n",
        "    plt.title(f\"model {model} accuracy\")\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.ylim(0.6, 1)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'valid'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOdFQyPCqzuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss(path, models):\n",
        "  '''Function to plot loss on train and validation sets.'''\n",
        "  for model in models:\n",
        "    history = joblib.load(os.path.join(path_to_results, model))\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title(f\"model {model} loss\")\n",
        "    plt.ylabel('loss')\n",
        "    #plt.ylim(0.6, 1)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'valid'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezG5t0AityWx",
        "colab_type": "text"
      },
      "source": [
        "Plots of loss and accuracy suggest that models are overfitted. The architectures are probably too big for the problem at hand and models are probably trained too much. So I will prune the networks and add Early Stopping callback, so that the network stops learning when the loss on validation set isn't falling anymore."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNGMAYp3Lxce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = {        \n",
        "          \"LSTM_300n\":      [LSTM(300),\n",
        "                                  Dense(1, activation=\"sigmoid\")],\n",
        "          \n",
        "          \"BiLSTM_100n\":          [Bidirectional(LSTM(100)),\n",
        "                                  Dense(1, activation=\"sigmoid\")],\n",
        "          \n",
        "          \"LSTM_200n_100n\":    [LSTM(200, return_sequences=True),\n",
        "                                  LSTM(100),\n",
        "                                  Dense(1, activation=\"sigmoid\")],\n",
        "          \n",
        "          \"LSTM_MultipleDense\":     [LSTM(100),\n",
        "                                  Dense(30, activation=\"relu\"),\n",
        "                                  Dense(1, activation=\"sigmoid\")],\n",
        "     \n",
        "         \n",
        "          \"Conv_Pool_LSTM\": [Conv1D(32,3),\n",
        "                                   MaxPooling1D(pool_size=2),\n",
        "                                   LSTM(100),\n",
        "                                   Dense(1, activation=\"sigmoid\")],\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}